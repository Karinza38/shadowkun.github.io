---                                                                                                                                                                                              
  layout: post
  title: LLM
---

## LLM

OpenAI 的强大模型们，被开源社区复刻得差不多了。

过去几个月，OpenAI 的 ChatGPT 彻底改变了聊天机器人领域的格局，也成为其他研究赶超的对象。

以 Meta 开源 LLaMA（直译为「大羊驼」）系列模型为起点，斯坦福大学等机构的研究人员先后在其上进行「二创」，开源了基于 LLaMA 的 Alpaca（羊驼）、Alpaca-Lora、Luotuo（骆驼）等轻量级类 ChatGPT 模型，大大降低了这类模型的研究、应用门槛，训练、推理成本一再降低。

由于「二创」过于丰富，生物学羊驼属的英文单词都快不够用了，但富有创意的研究者似乎总能给他们的模型找到新名字。近日，来自加州大学伯克利分校、卡内基梅隆大学、斯坦福大学、加州大学圣迭戈分校的研究者们又提出了一个新的模型 ——Vicuna（小羊驼）。这个模型也是基于 LLaMA，不过用到的是 13B 参数量的版本（作者表示，初步人工评测显示 13B 版本比 7B 版本模型要好不少，不过这不是一个严谨的结论）。

这个项目有趣的地方在于，作者在评测环节并没有通过某种「标准化考试」来测定模型性能（因为他们认为这些问题测不出模型在对话中的变通能力），而是让 GPT-4 当「考官」，看看 GPT-4 更倾向于 Vicuna-13B 还是其他基线模型的答案。结果显示，相比于现有的 SOTA 开源模型（LLaMA、Alpaca），GPT-4 在超过 90% 的问题中更倾向于 Vicuna，并且 Vicuna 在总分上达到了 ChatGPT 的 92%。

从个人使用下来看，确实效果还是不错的，尤其是 Chat GLM2 对于上下文长度的拓展，让使用起来更加容易了。